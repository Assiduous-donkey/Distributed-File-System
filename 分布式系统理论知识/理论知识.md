# 分布式系统理论知识点

## 分布式系统的定义和特点

分布式系统是若干独立计算机的集合，这些计算机对用户来说像是一个单一的系统。
系统中各节点硬件或软件进程是独立的，但节点之间又需要互相协作。

系统的设计要求：

- 使资源可访问：让用户能够方便地访问资源

- 透明性：隐藏资源和进程在多台计算机上分布这一事实

- 开放性：访问接口的标准化

- 可扩展性：系统在规模、地域和管理上的可扩展性。

## 分布式系统的可扩展性

包括三个方面的可扩展性：

1. 规模可扩展性：用户数量和进程数量增加

2. 地理可扩展性：节点之间的最大物理位置

3. 管理可扩展性：管理域的数量

可采用的扩展技术有：

1. 隐藏通信延迟：尽量避免等待远程服务对请求的响应(异步通信技术)

2. 分布式技术：在多台机器上划分数据并计算

3. 复制和缓存：在多个不同的机器上创建多个数据副本(如Web站点的镜像、文件缓存)

## 超级对等节点

维护一个索引或充当一个代理程序的节点称为超级对等节点。超级对等节点的作用是维护索引(其他节点的位置)、监控网络状态。

## 为什么分布式系统中多采用线程而不是进程

1. 避免不必要的阻塞：在多线程的进程中操作系统可以将CPU权限转交给进程的另一个线程

2. 更好地发挥并行性：一个具有多线程的进程可以在多核CPU上并行运行

3. 避免进程的上下文切换：线程共享相同的地址空间，线程的上下文切换可以独立于操作系统，且切换代价小。

## 远程过程调用(RPC)

RPC是一种通过网络从远程计算机程序上请求服务而不需要了解底层网络技术的协议。也就是将客户存根发出的本地调用转换为对服务器的本地调用，而客户和服务器都不会意识到有中间步骤的存在。

过程：

1. 客户过程以正常的方式调用客户存根，客户存根生成一个消息然后调用本地操作系统

2. 客户端操作系统将消息发送给远程服务器的操作系统，服务器操作系统再将消息交给服务器存根

3. 服务器存根提取参数然后调用服务器的本地方法，然后将结果返回给服务器存根。

4. 服务器存根生成一个消息然后调用服务器本地的操作系统，服务器操作系统将含有调用结果的消息发送给客户端操作系统

5. 客户端操作系统收到消息后交给客户存根，客户存根将结果从消息中提取出来返回给调用它的客户过程。

## socket网络通信

服务器过程：

1. 创建套接字并绑定到本地IP和端口

2. 设置套接字为监听模式准备接收客户端的请求

3. 等待客户端请求，接收到连接请求后返回一个新的对应于此次连接的套接字。

4. 用返回的套接字和客户端进行通信

客户端过程：

1. 创建套接字并绑定到本地IP和端口

2. 向服务器发出连接请求

3. 和服务器进行通信

## Chord算法

Chord算法是有关分布式散列表的一种算法。其中每个节点被赋予一个由M位构成的标识符，每个实体被赋予一个唯一的M位键值。所有节点构成一个逻辑上的环。
其中键值为K的实体存储在满足标识符≥K的最小标识符节点上(该节点称为K的后继者，记为succ(K))。

每个节点维护一个含有M项的表，称为指状表。其中节点p的表项为$FT_p[i]=succ(p+2^{i-1})$，i从1开始算起。

### 查找实体

寻找一个键值为K的实体时，在节点p上选择满足下式的表项=> 节点q= $FT_p[i]<=K<FT_p[i+1]$，则q为下一个要查找的节点。
若K大于p中的所有表项则取p的最后一个表项所指的节点作为下一个要查找的节点。
若K小于p的第一个表项则下一个要查找的节点为p的第一个表项所指的节点

### 维护指状表

每个节点q定期运行一个进程来与succ(q+1)联系并请求返回pred(succ(q+1))，即succ(q+1)的前继节点。若q=pred(succ(q+1))那么q就知道它的信息与其后继者是一致的。否则表明有新节点p加入环，切有q<p<=succ(q+1)，这就需要令$FT_q[1]=p$

### 新节点加入

新节点加入环时必须请求网络中已有的任何节点告知新节点它的后继者是谁。然后新节点请求其后继节点告知自己后继节点的前继节点是谁，这个前继节点将成为新节点的前继节点。

### 节点离开

节点将自己负责的索引交给自己的后继节点，并通知前继节点自己将离开，以便其前继节点能连接到要离开的节点的后继节点。

## 树结构目录

在树结构目录中，实体E的地址存储在叶节点或者中间节点上。中间节点包含了指向其孩子节点的指针。根节点知道所有实体的地址(根节点中的每一条位置记录都存储一个指向更低层子域目录节点的指针)

每一个节点代表一个域，根节点是最大的域。

### 查询

首先在叶节点上搜索，若该节点知道实体E则继续搜索下游指针，否则回退到父节点。向上搜索的过程最终会以到达根节点而停止。

### 插入实体E的副本

插入请求被转发到知道实体E地址的第一个节点(自底向上转发)，然后建立一条从第一个知道实体E的地址的节点到实体E的指针链。

## 实体的硬链接和软链接

硬链接：用于在命名图中按照指定路径搜索节点的路径名就是硬链接(允许一个文件有多个路径名————不同副本)

软链接：允许一个节点包含另外一个节点的路径名(类似与Windows下的快捷方式)

## 挂载点和挂接点

挂接点指在当前命名空间中用于存储外部名称空间的节点标识符的目录节点。
挂载点指外部名称空间中的目录节点。
在名称解析时若解析到一个挂载点则会返回一个指向该挂载点在网络中的位置的URL

## 逻辑时钟

**逻辑时钟可以用于在没有或未知UTC的情况下保障时间的准确性**。

若两个进程不交互则它们的时钟无需同步。所以重要的不是所有的进程在时间上完全一致，而是它们在事件发生的顺序上要达成一致。
因此逻辑时钟指的是**分布式系统中用于区分事件的发生顺序的时间机制**。

### 分配时间戳

若a和b是同一个进程的事件，并且a先于b发生(即a->b)，那么有C(a)＜C(b)。其中C(e)表示事件e发生的时间戳。
若a是信息m的发送方而b是信息的接收者，那么C(a)＜C(b)。

每个进程$P_i$维护一个计数器$C_i$：

- 当有新事件发生时$C_i+1$

- 当$P_i$发送一个消息m时，消息m得到一个时间戳 => $ts(m)=C_i$

- 当进程$P_j$收到消息m时调整自己的本地计数器$C_j$，令$C_j=max(C_j,ts(m))$

- 若进程$P_j$要继续传递消息m，相当于该进程有新事件发生，故要令其计数器+1

可以将事件所属的进程的标识附加到时间戳上以区分收到的具有相同时间戳的不同消息。

## 全序多播

全序多播是Lamport时间戳(逻辑时钟)的一个应用。即一次将所有的消息以相同的顺序传送给每个接收者的多播操作( 应用：在一个副本数据库上的并发更新在任何地方都应该是同样的顺序)。

### 全序多播的方式

进程$P_i$将加上时间戳的消息$m_i$发送给所有的进程，消息本身保存在本地队列中。
任何到达进程$P_j$的消息放在进程的本地队列中，根据它的时间戳进行排序，并向所有进程广播确认消息。

进程$P_j$在满足下面条件时会将消息$m_i$传递给它的应用程序(假定通信是可靠的且消息是FIFO排序)

- $m_i$位于$P_j$本地队列的队首(局部最小)

- 对于每个进程$P_k$，$P_j$的本地队列中存在一个消息$m_k$具有较大的时间戳(全局最小)

## 向量时钟

可以捕获时间的因果关系(逻辑时钟不行)，每个进程$P_i$维护一个向量时钟$VC_i$：

- $VC_i[i]$表示进程$P_i$的逻辑时钟(等于进程$P_i$发生的事件数)

- $VC_i[j]=k$表示进程$P_i$知道进程$P_j$已经发生了k个事件

因果依赖：ts(a)表示时间a发生时的向量时钟，若对于所有k，都有$ts(a)[k]<=ts(b)[k]$，则说明b因果依赖于a

维护向量时钟：

- $P_i$在执行一个事件之前先执行$VC_i[i]=VC_i[i]+1$

- 当$P_i$发送一个消息m给$P_j$时，也发送m的向量时钟ts(m)，其中$ts(m)=VC_i$，即当前的向量时钟

- 进程$P_j$收到消息m后修改自己的向量时钟为：对于任意k，令$VC_j[k]=max(VC_j[k],ts(m)[k])$

- 进程$P_j$要将消息发送给应用程序时要执行一次$VC_j[j]=VC_j[j]+1$

比较两个事件的时间戳，若其中一个向量时钟的每个元素都小于另一个向量时钟则这两个时间可能存在因果关系。

### 因果有序的多播

因果有序的多播借助向量时钟实现，比全序多播弱，当两个消息互相没有任何关系时以哪种顺序发送给应用程序并不重要。

### 强制的因果有序

进程$P_j$推迟向应用程序传递消息m(由进程$P_i$发送)直到：

- $ts(m)[i]=VC_j[i]+1$ ：表示消息m是进程$P_j$希望从进程$P_i$接收到的下一条消息

- $ts(m)[k]<=VC_j[k],k≠i$

## 分布式系统中多进程互斥的解决方案

### 基本方案

基于许可：如果进程需要访问临界区或者访问资源，需要从其他进程获得许可。
基于令牌：仅有一个令牌在进程之间传递，拥有令牌的进程可以访问临界区或者将令牌传递给其他进程。

### 具体算法

1. 基于许可的集中式方法：需要一个协作者，进程要访问共享资源时要向协作者发送一个请求消息说明要访问的资源并请求准许，若当前没有其他进程访问资源，协作者就发送准许的应答消息。(该方法存在单点故障问题，且若进程发出请求后被阻塞则进程无法区分是在等待资源还是协作者崩溃)

2. 基于许可的非集中式方法：假定每种资源有N个副本，每一个副本都有自己的协作者用于访问控制。进程只要获得大于N/2个协作者的大多数投票就可以访问资源。一个协作者总数立即响应请求。(存在的问题是若请求数量过多时可能请求都无法得到N/2个准许的应答消息，因为逻辑上一个节点同一时间只能处理一个请求)

3. 分布式算法(Ricart&Agrawala)：要求系统中事件发送的时间需要非常明确，进程要访问共享资源时构造一个消息(包括资源名、它的进程号和当前逻辑时间)然后发送给所有的其他进程，当所有其他进程返回给当前进程准许的应答消息后该进程才可以访问共享资源。(存在的问题是单点故障被N点故障代替，任何一个进程崩溃都会造成阻塞)
接收到请求的进程的决策分三种情况：

    - 若接收的进程没有访问资源也不想访问资源，则向发送者发送“准许”消息

    - 若接收者已获得对资源的访问，则不应答，但将该请求放入队列中。

    - 若接收者想访问资源但尚未访问，它将收到消息的时间戳与它发送给其他进程的消息的时间戳进行比较，时间戳较早的那个进程获胜(得到准许)。如果接收到的消息的时间戳比较早则返回“准许”消息；如果自己发送出去的消息的时间戳比较早则将收到的消息放入队列中且不发送任何应答消息。

4. 令牌环算法：将进程组织成逻辑环，令牌在这些进程之间传递，拥有令牌的进程允许进入临界区。不允许进程在释放资源后使用同一令牌立即再次访问资源(避免造成饥饿)

## 一致性模型

顺序一致性：任何执行结果都是相同的，好像**所有进程对数据存储的读写操作都是按照某种序列顺序执行的**，并且每个进程的操作按照程序所定制的顺序出现在这个序列中。
因果一致性：是一种弱化的顺序一致性模型。**所有的进程必须以相同的顺序看到具有潜在因果关系的写操作**。不同机器上可以以不同的顺序看到**并发写操作**。

上述一致性模型都属于以数据为中心的一致性模型。

以数据为中心的一致性模型适用于读写并重的数据存储。
以客户为中心的一致性模型适用于读多写少的数据存储(提供最终一致性)

最终一致性：如果很长一段时间内没有更新操作那么所有的副本将逐渐成为一致(可能在中间某一时刻出现数据不一致的情况)。

## 读写一致性和写读一致性

单调读：如果一个进程读取数据项X的值，那么该进程对X执行的任何后续操作将总是得到第一次读取的那个值或更新的值。
单调写：一个进程对数据项X执行的写操作必须在该进程对X执行任何后续写操作之前完成。

读写一致性(读建立在写之上)：一个进程对数据项X执行写操作的结果总是会被该进程对X执行的后续读操作看见。(Web页面更新)
写读一致性(写建立在读之上)：同一个进程对数据项X执行读操作之后的写操作，保证发送在与X读取的值相同或比之更新的值上。(用户只有在看到新闻的原文章之后才能看到它的回应文章)

上述模型都属于以客户为中心的一致性模型。

## 基于主备份协议的复制协议

1. 远程写协议：要在数据项X上执行一个写操作的进程会把该操作转发给X的主服务器。该主服务器在其X的本地副本上执行更新操作，随后把该更新转发给备份服务器，让每个备份服务器也执行这个更新操作并往主服务器返回确认消息。当所有备份服务器更新了它们的本地副本后主服务器返回一个确认消息给初始进程。(缺点是进程可能需要等待较长时间)

2. 本地写协议：当一个进程需要更新数据项X时先定位X的主副本，然后把它移到自己的位置上(本地缓存)，再进行写操作。本地缓存回复给进程操作执行完成后，新的X的主服务器通知备份服务器进行更新。(允许在本地执行多个连续的写操作且在离线模式下进行计算)

## CAP

一致性(Consistence)：同一数据的不同备份要保持一致才可被访问
可用性(Availability)：确保系统能提供服务
分区容错性(Partition tolerance)：网络节点之间无法通信的情况下节点被隔离产生了网络分区，但整个系统仍然可以工作

## 分布式系统的冗余方式

1. 信息冗余：在数据单元添加**额外的位数据**使错乱的位恢复正常

2. 时间冗余：若系统出错，则因为出错而未执行完成的动作可以再次执行

3. 物理冗余：添加额外的数据副本

## 两阶段提交协议

是一种分布式提交协议，一个操作要么被进程组中的每个成员执行，要么进程组的每个成员都不执行。

流程：
第一阶段：协作者(前端/客户端)发送投票请求给参与者(处理事务的节点/组件)。参与者收到请求后返回commit或者abort消息。若发送的是abort则中止参与者本地计算。
第二阶段：协作者收集所有投票结果，若结果都是commit则发送global-commit信息给所有参与者，否则发送global-abort消息。参与者接收到global信息后执行相应的操作

## 共识

共识指的是使所有非故障进程就由谁来执行命令(在有限步骤内)达成一致。

## paxos协议

涉及到的定义：

    - proposer：发起paxos的进程

    - acceptor：存储节点(拥有接收、处理和存储消息)

    - round：轮数

    - last_rnd：acceptor看到的最大的round，由这个值来识别哪一个进程可以写

    - value round number(vrnd)：指acceptor接受value时的round(当有多于半数个acceptor接受某个值时，该值被确定)

流程:

第一阶段，acceptor收到phase-1请求时执行：

    - 若请求中的round比acceptor的last_rnd小则拒绝请求(表明该请求不是最新)

    - 否则将请求中的round保存到acceptor本地的last_rnd(从此这个acceptor只接受带有这个round的proposer发出的phase-2请求)

    - acceptor返回应答并带上自己之前的last_rnd和之前已经接受的value

第一阶段，proposer收到acceptor发回的应答后执行：

    - 若应答中的last_rnd大于proposer发出的round，则退出

    - 否则从所有应答中选择vrnd最大的round

    - 若所有应答的value都为空则可以选择自己要写入的value

    - 若应答不超过半数，则退出

第二阶段，对于proposer：

    - 发送phase-2请求并带上round和上一阶段决定的value

第二阶段，对于acceptor：

    - 拒绝round不等于本地last_rnd的请求(保证没有其他proposer在此过程中写入其他值)

    - 将phase-2请求中的value写入本地，记此value为已接受的值

第三阶段，acceptor发送phase-3消息到所有的learner角色告诉它们某个值被确定(多数情况下learner记为proposer)

存在的问题：可能会造成活锁，即多个proposer并发对1个值允许paxos协议时可能会互相覆盖对方的round然后提升自己的round并再次尝试，然后不断产生冲突。

## MapReduce

一种编程模型，主要应用于海量数据的并行计算，可以分为两部分理解：

map：映射过程，把一组数据按照某种map函数映射成新的数据(将输入分解为键值对)
reduce：归约过程，把若干组映射结果进行汇总并输出(将相同键的值合并)

还有一个shuffle操作，是对数据映射进行排序、分组和拷贝。实际上该操作被分为两部分，一部分在map执行一部分在reduce执行。
